{"cells":[{"cell_type":"markdown","source":["Name: Arjun Bhan                   \n","UNI: AB5666"],"metadata":{"id":"8rBMpHqtN8HS"}},{"cell_type":"markdown","source":["# MNIST MLP Digit Recognition Network\n","\n","For this problem, you will code a basic digit recognition network. The data are images which specify the digits 1 to 10 as (1, 28, 28) data - this data is black and white images. Each pixed of the image is an intensity between 0 and 255, and together the (1, 28, 28) pixel image can be visualized as a picture of a digit. The data is given to you as $\\{(x^{(i)}, y^{(i)})\\}_{i=1}^{N}$ where $y$ is the given label and x is the (1, 28, 28) data. This data will be gotten from `torchvision`, a repository of computer vision data and models.\n","\n","Highlevel, the model and notebook goes as follows:\n","*   You first download the data and specify the batch size of B = 16. Each image will need to be turned from a (1, 28, 28) volume into a vector of dimension 784 = 1 * 28 * 28. So each batch will be of size (16, 784).\n","*   Then, you pass the model through two hidden layers, one of dimension (784, 32) and another of dimension (32, 16). After each linear map, you pass the data through a TanH nonlinearity.\n","*   Finally, you pass the data through a (32, 10) linear layer and you return the log softmax of the data.\n","*   What objective do you use? Be careful!\n","*   How do you compute accuracy both manually and with torchmetrics?\n","*   How do you compute AUROC?\n","\n","Accuracy should be higher than 85%. If you use another nonlinearity, like ReLU, you might get higher. Play around with this but submit working code that does better than 85%.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"y5XzVh-J0-fu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfKuo0JFxJ7d","outputId":"691a57cd-cc95-4d40-8dfc-05e9011b9a74"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (17.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UDIb4ldyj2C"},"outputs":[],"source":["import torchvision\n","from torchmetrics import Accuracy\n","from torchvision import transforms\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torchmetrics"]},{"cell_type":"code","source":["\n","SEED = 1\n","torch.manual_seed(SEED)"],"metadata":{"id":"PdLoOr08AUY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLD0oQmgxxlR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e96b272c-0933-4c9f-a71a-23c5b7d9fe80"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 20555791.02it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 38237277.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 29950463.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 17558091.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n","\n"]}],"source":["image_path = './'\n","\n","\n","transform = transforms.Compose([\n","      transforms.ToTensor()\n","])\n","\n","mnist_train_dataset = torchvision.datasets.MNIST(\n","    root=image_path,\n","    train=True,\n","    transform = transform,\n","    download=True\n","  )\n","\n","mnist_test_dataset = torchvision.datasets.MNIST(\n","    root=image_path,\n","    train=False,\n","    transform=transform,\n","    download=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGLuLaEXyzoD"},"outputs":[],"source":["BATCH_SIZE = 64\n","LR = 0.001\n","EPOCHS = 20\n","train_dl =  DataLoader(mnist_train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n","test_dl =  DataLoader(mnist_test_dataset, batch_size = BATCH_SIZE, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjLznvm8xqaT"},"outputs":[],"source":["class MLPClassifier(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","    self.linear1 =  nn.Linear(784, 32)\n","    self.linear2 = nn.Linear(32, 16)\n","    self.linear3 = nn.Linear(16, 10)\n","\n","  def forward(self, x):\n","    x = x.reshape(-1,784)\n","\n","    x = self.linear1(x)\n","\n","    x = nn.Tanh()(x)\n","\n","    x = self.linear2(x)\n","\n","    x = nn.Tanh()(x)\n","\n","    x = self.linear3(x)\n","\n","\n","    return nn.functional.log_softmax(x, dim=1)\n","\n","model = MLPClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zu4Z0aptxqcu","outputId":"9b857db3-26bb-4499-caf2-de674ba12560"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n","  warnings.warn(*args, **kwargs)  # noqa: B028\n"]},{"output_type":"stream","name":"stdout","text":["Train Metrics Epoch 0 Loss 2.2644 Accuracy 0.2251 AUROC 0.7630\n","Test Metrics Epoch 0 Loss 2.2155 Accuracy 0.3305 AUROC 0.8787\n","Train Metrics Epoch 1 Loss 2.1683 Accuracy 0.4055 AUROC 0.8960\n","Test Metrics Epoch 1 Loss 2.1078 Accuracy 0.5435 AUROC 0.9134\n","Train Metrics Epoch 2 Loss 2.0493 Accuracy 0.5686 AUROC 0.9187\n","Test Metrics Epoch 2 Loss 1.9734 Accuracy 0.6048 AUROC 0.9312\n","Train Metrics Epoch 3 Loss 1.9050 Accuracy 0.6139 AUROC 0.9334\n","Test Metrics Epoch 3 Loss 1.8189 Accuracy 0.6390 AUROC 0.9444\n","Train Metrics Epoch 4 Loss 1.7482 Accuracy 0.6353 AUROC 0.9408\n","Test Metrics Epoch 4 Loss 1.6618 Accuracy 0.6526 AUROC 0.9492\n","Train Metrics Epoch 5 Loss 1.5959 Accuracy 0.6420 AUROC 0.9476\n","Test Metrics Epoch 5 Loss 1.5162 Accuracy 0.6528 AUROC 0.9556\n","Train Metrics Epoch 6 Loss 1.4587 Accuracy 0.6486 AUROC 0.9536\n","Test Metrics Epoch 6 Loss 1.3877 Accuracy 0.6642 AUROC 0.9588\n","Train Metrics Epoch 7 Loss 1.3386 Accuracy 0.6676 AUROC 0.9585\n","Test Metrics Epoch 7 Loss 1.2751 Accuracy 0.6939 AUROC 0.9626\n","Train Metrics Epoch 8 Loss 1.2336 Accuracy 0.6986 AUROC 0.9626\n","Test Metrics Epoch 8 Loss 1.1760 Accuracy 0.7282 AUROC 0.9674\n","Train Metrics Epoch 9 Loss 1.1413 Accuracy 0.7330 AUROC 0.9663\n","Test Metrics Epoch 9 Loss 1.0885 Accuracy 0.7586 AUROC 0.9729\n","Train Metrics Epoch 10 Loss 1.0598 Accuracy 0.7625 AUROC 0.9686\n","Test Metrics Epoch 10 Loss 1.0111 Accuracy 0.7843 AUROC 0.9746\n","Train Metrics Epoch 11 Loss 0.9878 Accuracy 0.7849 AUROC 0.9723\n","Test Metrics Epoch 11 Loss 0.9427 Accuracy 0.8056 AUROC 0.9761\n","Train Metrics Epoch 12 Loss 0.9244 Accuracy 0.8023 AUROC 0.9739\n","Test Metrics Epoch 12 Loss 0.8825 Accuracy 0.8203 AUROC 0.9779\n","Train Metrics Epoch 13 Loss 0.8685 Accuracy 0.8163 AUROC 0.9751\n","Test Metrics Epoch 13 Loss 0.8297 Accuracy 0.8280 AUROC 0.9802\n","Train Metrics Epoch 14 Loss 0.8195 Accuracy 0.8257 AUROC 0.9770\n","Test Metrics Epoch 14 Loss 0.7833 Accuracy 0.8357 AUROC 0.9811\n","Train Metrics Epoch 15 Loss 0.7763 Accuracy 0.8335 AUROC 0.9776\n","Test Metrics Epoch 15 Loss 0.7424 Accuracy 0.8415 AUROC 0.9836\n","Train Metrics Epoch 16 Loss 0.7384 Accuracy 0.8400 AUROC 0.9793\n","Test Metrics Epoch 16 Loss 0.7064 Accuracy 0.8463 AUROC 0.9845\n","Train Metrics Epoch 17 Loss 0.7049 Accuracy 0.8445 AUROC 0.9797\n","Test Metrics Epoch 17 Loss 0.6747 Accuracy 0.8507 AUROC 0.9870\n","Train Metrics Epoch 18 Loss 0.6752 Accuracy 0.8488 AUROC 0.9810\n","Test Metrics Epoch 18 Loss 0.6466 Accuracy 0.8550 AUROC 0.9854\n","Train Metrics Epoch 19 Loss 0.6487 Accuracy 0.8534 AUROC 0.9813\n","Test Metrics Epoch 19 Loss 0.6215 Accuracy 0.8593 AUROC 0.9860\n"]}],"source":["loss_fn = torch.nn.NLLLoss()\n","\n","optimizer = torch.optim.SGD(model.parameters(),lr =   LR)\n","\n","torch.manual_seed(SEED)\n","for epoch in range(EPOCHS):\n","    accuracy_hist_train = 0\n","    auroc_hist_train = 0.0\n","    loss_hist_train = 0\n","    for x_batch, y_batch in train_dl:\n","        pred = model(x_batch)\n","        loss = loss_fn(pred,y_batch)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","\n","        loss_hist_train += loss.item() * len(y_batch)\n","\n","        optimizer.step()\n","\n","        optimizer.zero_grad()\n","\n","\n","        is_correct_1 = (pred.argmax(dim = 1) == y_batch)\n","\n","\n","        accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n","        is_correct_2 = accuracy(pred.argmax(dim = 1), y_batch).item() * len(y_batch)\n","        assert(is_correct_1.sum() ==  is_correct_2)\n","\n","        accuracy_hist_train += is_correct_1.sum().item()\n","\n","        auroc =torchmetrics.AUROC(task=\"multiclass\", num_classes=10)\n","        auroc_hist_train += auroc(pred, y_batch) * BATCH_SIZE\n","    accuracy_hist_train /= len(train_dl.dataset)\n","    auroc_hist_train /= len(train_dl.dataset)\n","    loss_hist_train /= len(train_dl.dataset)\n","    print(f'Train Metrics Epoch {epoch} Loss {loss_hist_train:.4f} Accuracy {accuracy_hist_train:.4f} AUROC {auroc_hist_train:.4f}')\n","\n","    accuracy_hist_test = 0\n","    auroc_hist_test = 0.0\n","    loss_hist_test = 00\n","\n","    with torch.no_grad():\n","      accuracy_hist_test = 0\n","      auroc_hist_test = 0.0\n","      for x_batch, y_batch in test_dl:\n","          pred = model(x_batch)\n","\n","          loss = loss_fn(pred,y_batch)\n","\n","          loss_hist_test += x_batch.size(0) * loss.item()\n","\n","\n","          accuracy = Accuracy(task=\"multiclass\", num_classes=10)\n","          is_correct =  accuracy(pred.argmax(dim = 1), y_batch).item() * len(y_batch)\n","\n","          accuracy_hist_test +=  accuracy(pred.argmax(dim = 1), y_batch).item() * len(y_batch)\n","\n","          auroc =torchmetrics.AUROC(task=\"multiclass\", num_classes=10)\n","          auroc_hist_test +=  auroc(pred, y_batch) * BATCH_SIZE\n","      accuracy_hist_test /= len(test_dl.dataset)\n","      auroc_hist_test /= len(test_dl.dataset)\n","      loss_hist_test /= len(test_dl.dataset)\n","      print(f'Test Metrics Epoch {epoch} Loss {loss_hist_test:.4f} Accuracy {accuracy_hist_test:.4f} AUROC {auroc_hist_test:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8MvVnJixqhq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"358dab55-79f7-4aca-a9a2-8e6ba4629220"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total Final Train accuracy: 0.8555\n","Total Final Test accuracy: 0.8593\n"]}],"source":["\n","pred = model(mnist_train_dataset.data/255.)\n","is_correct =  (pred.argmax(dim = 1) == mnist_train_dataset.targets).float()\n","print(f'Total Final Train accuracy: {is_correct.mean():.4f}')\n","\n","pred =  model(mnist_test_dataset.data/255.)\n","is_correct =  (pred.argmax(dim = 1) == mnist_test_dataset.targets).float()\n","print(f'Total Final Test accuracy: {is_correct.mean():.4f}')\n"]},{"cell_type":"code","source":[],"metadata":{"id":"bzQZ9EPx0ETv"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}