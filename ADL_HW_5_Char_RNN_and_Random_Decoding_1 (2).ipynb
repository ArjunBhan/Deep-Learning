{"cells":[{"cell_type":"markdown","source":["Name: Arjun Bhan  UNI: AB5666"],"metadata":{"id":"qqVnq5eXjz7f"},"id":"qqVnq5eXjz7f"},{"cell_type":"code","execution_count":null,"id":"97ab5757","metadata":{"id":"97ab5757"},"outputs":[],"source":["from tqdm import tqdm\n","import torch.nn as nn\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"id":"7bd215dd","metadata":{"id":"7bd215dd"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"64c0320b","metadata":{"id":"64c0320b"},"source":["### Get the data and process\n","- This is the Mysterious island found in Project Gutenberg."]},{"cell_type":"code","execution_count":null,"id":"d4e64a98","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4e64a98","outputId":"d8fed805-e8c8-4516-e0e1-dbcd3213935b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'L', ' ', ')', 'G', 'V', 'H', 'Y', 'd', '2', '.', 's', '&', 'R', 'y', '(', '’', '!', '9', 'k', 'i', '?', 'C', 'm', '\\n', 'z', '”', '-', 'X', 'n', 'B', 'c', 'j', 'Z', '\"', 'q', 'f', 'S', 'Q', 'P', '8', 'T', '4', 'U', 'I', '3', 'a', '“', 'u', 'e', ':', '7', 'J', 'r', 'A', 'v', '%', 'M', '5', '$', 'p', 'E', 'x', 'F', '=', '*', 'b', 'w', '/', 'o', 'g', 'W', ',', 't', '‘', 'h', \"'\", ';', '1', '0', 'l', '6', 'K', 'O', 'N', 'D'}\n","Total Length: 1130711\n","Unique Characters: 85\n"]}],"source":["with open('/content/1268-0.txt', 'r', encoding=\"utf8\") as fp:\n","    text=fp.read()\n","\n","start_indx = text.find('THE MYSTERIOUS ISLAND')\n","end_indx = text.find('End of the Project Gutenberg')\n","\n","text = text[start_indx:end_indx]\n","char_set = set(text)\n","print(char_set)\n","print('Total Length:', len(text))\n","print('Unique Characters:', len(char_set))\n","assert(len(text) == 1130711)\n","assert(len(char_set) == 85)"]},{"cell_type":"markdown","id":"76393bdb","metadata":{"id":"76393bdb"},"source":["### Tokenze and get other helpers\n","- We do this manually since everything is character based."]},{"cell_type":"code","execution_count":null,"id":"3a445114","metadata":{"id":"3a445114","outputId":"538aea6b-649f-4293-8fb4-f2369fd68f32","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Text encoded shape:  (1130711,)\n","THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n","[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"]}],"source":["chars_sorted = sorted(char_set)\n","\n","\n","char2int = {curChar: curInd for curInd, curChar in enumerate(chars_sorted)}\n","int2char = np.array(chars_sorted)\n","\n","text_encoded = np.array([char2int[i] for i in text], dtype= np.int32)\n","\n","print('Text encoded shape: ', text_encoded.shape)\n","\n","print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n","print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(int2char[text_encoded[15:21]]))"]},{"cell_type":"markdown","id":"720cd752","metadata":{"id":"720cd752"},"source":["#### Examples"]},{"cell_type":"code","execution_count":null,"id":"e2743a57","metadata":{"id":"e2743a57","outputId":"265db139-6b59-4067-d53c-00951f616c8e","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Text encoded shape:  (1130711,)\n","THE MYSTERIOUS       == Encoding ==>  [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n","[37 47 40 29 42 32]  == Reverse  ==>  ISLAND\n"]}],"source":["print('Text encoded shape: ', text_encoded.shape)\n","print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n","print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(int2char[text_encoded[15:21]]))"]},{"cell_type":"code","execution_count":null,"id":"367e733d","metadata":{"id":"367e733d"},"outputs":[],"source":["assert(\n","    np.array_equal(\n","    text_encoded[:15],\n","        [48, 36, 33, 1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1]\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"id":"2cdcafe4","metadata":{"id":"2cdcafe4"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"0c418ca0","metadata":{"id":"0c418ca0"},"source":["### Process the data and get the data loader"]},{"cell_type":"code","execution_count":null,"id":"f429dc3d","metadata":{"id":"f429dc3d"},"outputs":[],"source":["seq_length = 40\n","chunk_size = seq_length + 1\n","\n","\n","chunckAmount = len(text_encoded)//chunk_size\n","text_chunks = []\n","for i in range(len(text_encoded)-chunk_size + 1):\n","  text_chunks.append(text_encoded[i:i+chunk_size])\n"]},{"cell_type":"code","execution_count":null,"id":"e329fffd","metadata":{"id":"e329fffd"},"outputs":[],"source":["class TextDataset(Dataset):\n","    def __init__(self, text_chunks):\n","        self.text_chunks = text_chunks\n","\n","    def __len__(self):\n","        return len(self.text_chunks)\n","\n","    def __getitem__(self, idx):\n","        text_chunk = self.text_chunks[idx]\n","\n","\n","        return text_chunk[0:40], text_chunk[1:41]\n","\n","seq_dataset = TextDataset(torch.tensor(text_chunks))"]},{"cell_type":"code","execution_count":null,"id":"71328555","metadata":{"id":"71328555","outputId":"43794d71-d3c0-4046-add4-884e7617bae9","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([40]) torch.Size([40])\n","Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n","Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n","\n","torch.Size([40]) torch.Size([40])\n","Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n","Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n","\n"]}],"source":["for i, (seq, target) in enumerate(seq_dataset):\n","    print(seq.shape, target.shape)\n","    print('Input (x):', repr(''.join(int2char[seq])))\n","    print('Target (y):', repr(''.join(int2char[target])))\n","    print()\n","    if i == 1:\n","        break"]},{"cell_type":"code","execution_count":null,"id":"ebb989c3","metadata":{"id":"ebb989c3"},"outputs":[],"source":["device = torch.device(\"cpu\")"]},{"cell_type":"code","source":[],"metadata":{"id":"ziTi7-O4meHB"},"id":"ziTi7-O4meHB","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"a881b316","metadata":{"id":"a881b316"},"outputs":[],"source":["batch_size = 64\n","torch.manual_seed(1)\n","seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"]},{"cell_type":"code","execution_count":null,"id":"0f77f7f8","metadata":{"id":"0f77f7f8"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"45ed0b2f","metadata":{"id":"45ed0b2f"},"source":["### Write the models"]},{"cell_type":"code","execution_count":null,"id":"1b4cbf1e","metadata":{"id":"1b4cbf1e"},"outputs":[],"source":["class RNN(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","        self.rnn_hidden_size = rnn_hidden_size\n","\n","        self.rnn = nn.LSTM(input_size = embed_dim, hidden_size=rnn_hidden_size, batch_first=True)\n","\n","\n","        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n","\n","    def forward(self, text, hidden=None, cell=None):\n","        out = self.embedding(text)\n","\n","        if hidden is not None:\n","            out, (hidden, cell) = self.rnn(out, (hidden, cell))\n","        else:\n","            out, (hidden, cell) = self.rnn(out)\n","\n","        out = self.fc(out)\n","\n","        return out, (hidden, cell)\n","\n","    def init_hidden(self, batch_size):\n","        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n","        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n","        return hidden.to(device), cell.to(device)"]},{"cell_type":"code","execution_count":null,"id":"f16c03dc","metadata":{"id":"f16c03dc"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"00789dfd","metadata":{"id":"00789dfd"},"source":["### Do this right way - across all data all at once!"]},{"cell_type":"code","execution_count":null,"id":"33380607","metadata":{"id":"33380607","outputId":"58da8141-c79d-4cc0-8a04-3360d78a24e4","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNN(\n","  (embedding): Embedding(85, 256)\n","  (rnn): LSTM(256, 512, batch_first=True)\n","  (fc): Linear(in_features=512, out_features=85, bias=True)\n",")"]},"metadata":{},"execution_count":58}],"source":["vocab_size = len(int2char)\n","embed_dim = 256\n","rnn_hidden_size = 512\n","\n","torch.manual_seed(1)\n","model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n","model = model.to(device)\n","model"]},{"cell_type":"code","execution_count":null,"id":"2f47f48a","metadata":{"id":"2f47f48a","outputId":"a603a69b-4f36-4978-95ae-afdc4b27e7f6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0 loss: 4.4364\n","Epoch 100 loss: 1.6833\n","Epoch 200 loss: 1.4937\n","Epoch 300 loss: 1.3673\n","Epoch 400 loss: 1.3395\n","Epoch 500 loss: 1.4198\n","Epoch 600 loss: 1.3841\n","Epoch 700 loss: 1.2793\n","Epoch 800 loss: 1.3617\n","Epoch 900 loss: 1.2560\n","Epoch 1000 loss: 1.3461\n","Epoch 1100 loss: 1.2049\n","Epoch 1200 loss: 1.2541\n","Epoch 1300 loss: 1.2249\n","Epoch 1400 loss: 1.2720\n","Epoch 1500 loss: 1.2072\n","Epoch 1600 loss: 1.2968\n","Epoch 1700 loss: 1.2175\n","Epoch 1800 loss: 1.2203\n","Epoch 1900 loss: 1.2118\n","Epoch 2000 loss: 1.2050\n","Epoch 2100 loss: 1.1825\n","Epoch 2200 loss: 1.1912\n","Epoch 2300 loss: 1.2353\n","Epoch 2400 loss: 1.2758\n","Epoch 2500 loss: 1.2641\n","Epoch 2600 loss: 1.1490\n","Epoch 2700 loss: 1.1978\n","Epoch 2800 loss: 1.1520\n","Epoch 2900 loss: 1.1824\n","Epoch 3000 loss: 1.2312\n","Epoch 3100 loss: 1.2092\n","Epoch 3200 loss: 1.1566\n","Epoch 3300 loss: 1.1856\n","Epoch 3400 loss: 1.1772\n","Epoch 3500 loss: 1.1998\n","Epoch 3600 loss: 1.2040\n","Epoch 3700 loss: 1.2268\n","Epoch 3800 loss: 1.1719\n","Epoch 3900 loss: 1.1775\n","Epoch 4000 loss: 1.1764\n","Epoch 4100 loss: 1.1541\n","Epoch 4200 loss: 1.1799\n","Epoch 4300 loss: 1.1630\n","Epoch 4400 loss: 1.2396\n","Epoch 4500 loss: 1.1311\n","Epoch 4600 loss: 1.1447\n","Epoch 4700 loss: 1.1147\n","Epoch 4800 loss: 1.1667\n","Epoch 4900 loss: 1.1396\n","Epoch 5000 loss: 1.1529\n","Epoch 5100 loss: 1.1323\n","Epoch 5200 loss: 1.1419\n","Epoch 5300 loss: 1.1277\n","Epoch 5400 loss: 1.1513\n","Epoch 5500 loss: 1.1962\n","Epoch 5600 loss: 1.1441\n","Epoch 5700 loss: 1.1446\n","Epoch 5800 loss: 1.1677\n","Epoch 5900 loss: 1.1716\n","Epoch 6000 loss: 1.1832\n","Epoch 6100 loss: 1.1526\n","Epoch 6200 loss: 1.1937\n","Epoch 6300 loss: 1.1760\n","Epoch 6400 loss: 1.1065\n","Epoch 6500 loss: 1.1874\n","Epoch 6600 loss: 1.1378\n","Epoch 6700 loss: 1.1774\n","Epoch 6800 loss: 1.1006\n","Epoch 6900 loss: 1.1031\n","Epoch 7000 loss: 1.2215\n","Epoch 7100 loss: 1.0802\n","Epoch 7200 loss: 1.1376\n","Epoch 7300 loss: 1.1400\n","Epoch 7400 loss: 1.1838\n","Epoch 7500 loss: 1.1074\n","Epoch 7600 loss: 1.2195\n","Epoch 7700 loss: 1.1794\n","Epoch 7800 loss: 1.1711\n","Epoch 7900 loss: 1.1167\n","Epoch 8000 loss: 1.0837\n","Epoch 8100 loss: 1.1218\n","Epoch 8200 loss: 1.1324\n","Epoch 8300 loss: 1.1379\n","Epoch 8400 loss: 1.1600\n","Epoch 8500 loss: 1.1456\n","Epoch 8600 loss: 1.2349\n","Epoch 8700 loss: 1.1468\n","Epoch 8800 loss: 1.1892\n","Epoch 8900 loss: 1.1517\n","Epoch 9000 loss: 1.1266\n","Epoch 9100 loss: 1.1263\n","Epoch 9200 loss: 1.1365\n","Epoch 9300 loss: 1.1855\n","Epoch 9400 loss: 1.1415\n","Epoch 9500 loss: 1.1256\n","Epoch 9600 loss: 1.1518\n","Epoch 9700 loss: 1.1416\n","Epoch 9800 loss: 1.1475\n","Epoch 9900 loss: 1.1557\n"]}],"source":["criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n","\n","num_epochs = 10000\n","\n","torch.manual_seed(1)\n","seq_dl_iter = iter(seq_dl)\n","\n","for epoch in range(num_epochs):\n","      hidden, cell = model.init_hidden(batch_size)\n","      try:\n","        seq_batch, target_batch = next(seq_dl_iter)\n","      except StopIteration:\n","        seq_dl_iter = iter(seq_dl)\n","        seq_batch, target_batch = next(seq_dl_iter)\n","      seq_batch = seq_batch.to(device)\n","      target_batch = target_batch.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      loss = 0\n","\n","      logits, _ = model(seq_batch, hidden, cell)\n","\n","\n","\n","      loss += criterion(logits.view(batch_size * seq_length, -1), target_batch.view(batch_size * seq_length).long())\n","\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      loss = loss.item()\n","\n","      if epoch % 100 == 0:\n","          print(f'Epoch {epoch} loss: {loss:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"0f398f67","metadata":{"id":"0f398f67","outputId":"68a5276a-d2df-4e88-c82f-8b744492d243","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilities: tensor([[0.0159, 0.1173, 0.8668]])\n","[[1]\n"," [2]\n"," [2]\n"," [2]\n"," [2]\n"," [1]\n"," [2]\n"," [2]\n"," [2]\n"," [2]]\n"]}],"source":["from torch.distributions.categorical import Categorical\n","\n","torch.manual_seed(1)\n","\n","logits = torch.tensor([[-1.0, 1.0, 3.0]])\n","\n","print('Probabilities:', torch.softmax(logits, dim = 1))\n","\n","m = torch.distributions.Categorical(torch.softmax(logits,dim = -1))\n","samples = m.sample((10,))\n","\n","print(samples.numpy())"]},{"cell_type":"code","execution_count":null,"id":"81ec176d","metadata":{"id":"81ec176d"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"0547467d","metadata":{"id":"0547467d"},"source":["### Random decoding.\n","- This compounds problems: once you make a mistake, you can't undo it."]},{"cell_type":"code","execution_count":null,"id":"614fb236","metadata":{"id":"614fb236","outputId":"a3c582bb-19c9-4cdb-d5fc-62140f54c2aa","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["The island is on board, either the bead displange under the water on the\n","rate--that was blunded birds, the maneud coupless the retreat werence forth winted to underce, for in coast, his arms was no chumntannes, indeed.\n","\n","Cyrus Harding recounted them seen syout tusily, was to be sought. Leriate is breathey to any effect of a mile.\n","\n","The eyes observated him all that time reasoning to the mysterious.\n","There the reporter and Herbert that was therefore, they prought, Cyrus Harding.\n","\n","The ship of the fabrication, a\n"]}],"source":["def random_sample(\n","    model,\n","    starting_str,\n","    len_generated_text=500,\n","):\n","\n","    # Encode starting string into a tensor using char2str.\n","    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n","\n","    # Reshape to be 1 by ??? - let PyTorch figure this out.\n","    encoded_input = encoded_input.view(1,-1)\n","\n","    # This will be what you generate, but it starts off with something.\n","    generated_str = starting_str\n","\n","    # Put model in eval mode. This matters if we had dropout o batch / layer norms.\n","    model.eval()\n","\n","    hidden, cell = model.init_hidden(1)\n","\n","    hidden = hidden.to(device)\n","\n","    cell = cell.to(device)\n","\n","\n","    for c in range(len(starting_str)-1):\n","        out = encoded_input[:, c].view(1,1)\n","        _, (hidden, cell) = model(out, hidden, cell)\n","\n","\n","    last_char = encoded_input[:, -1]\n","\n","\n","    for i in range(len_generated_text):\n","\n","\n","        logits, (hidden, cell) = model(last_char.reshape(1,1), hidden, cell)\n","\n","        logits = logits.view(-1)\n","\n","        m = torch.distributions.Categorical(logits = logits)\n","\n","        last_char = m.sample()\n","\n","\n","        generated_str += int2char[last_char]\n","\n","    return generated_str\n","\n","torch.manual_seed(1)\n","model.to(device)\n","print(random_sample(model, starting_str='The island'))"]},{"cell_type":"code","source":[],"metadata":{"id":"JH8G5SSEhPIK"},"id":"JH8G5SSEhPIK","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}