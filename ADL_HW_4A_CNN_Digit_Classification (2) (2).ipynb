{"cells":[{"cell_type":"markdown","source":["Name: Arjun Bhan UNI: AB5666"],"metadata":{"id":"FNjJiUMzOu1S"}},{"cell_type":"markdown","metadata":{"id":"y5XzVh-J0-fu"},"source":["# MNIST CNN Digit Recognition Network\n","\n","For this problem, you will code a basic digit recognition network. The data are images which specify the digits 1 to 10 as (1, 28, 28) data - this data is black and white images. Each pixed of the image is an intensity between 0 and 255, and together the (1, 28, 28) pixel image can be visualized as a picture of a digit. The data is given to you as $\\{(x^{(i)}, y^{(i)})\\}_{i=1}^{N}$ where $y$ is the given label and x is the (1, 28, 28) data. This data will be gotten from `torchvision`, a repository of computer vision data and models.\n","\n","Highlevel, the model and notebook goes as follows:\n","*   You first download the data and specify the batch size of B = 16. Each image will need to be turned from a (1, 28, 28) volume into a serious of other volumes either via convolutional layers or max pooling layers.\n","*   You will pass the data through several layers to built a CNN classfier. Use the hints below to get the right dimensions and figure out what the layers should be. Be careful with the loss function. Add regularization (L1 and L2) manually.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GfKuo0JFxJ7d","outputId":"cd43ecea-6caa-4606-dc60-95b9c5672ea8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"]}],"source":["!pip install torchmetrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8UDIb4ldyj2C"},"outputs":[],"source":["import torchvision\n","from torchvision import transforms\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","import torchmetrics\n","from torchmetrics import Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PdLoOr08AUY5"},"outputs":[],"source":["SEED = 1\n","torch.manual_seed(SEED)\n","_FILL_ = '_FILL_'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jLD0oQmgxxlR"},"outputs":[],"source":["image_path = './'\n","\n","transform = transforms.Compose([transforms.ToTensor()])\n","\n","mnist_train_dataset = torchvision.datasets.MNIST(\n","    root = image_path, train = True, transform = transform, download = True\n","  )\n","\n","mnist_test_dataset = torchvision.datasets.MNIST(\n","    root = image_path, train = False, transform = transform, download = True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGLuLaEXyzoD"},"outputs":[],"source":["BATCH_SIZE = 16\n","LR = 0.1\n","L1_WEIGHT = 1e-10\n","L2_WEIGHT = 1e-12\n","EPOCHS = 20\n","train_dl = DataLoader(mnist_train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n","test_dl = DataLoader(mnist_test_dataset, batch_size = BATCH_SIZE, shuffle = True)"]},{"cell_type":"code","source":["mnist_train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GnUcB8kd5ah","outputId":"b7b84758-5178-4e33-d906-42cbad4655f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset MNIST\n","    Number of datapoints: 60000\n","    Root location: ./\n","    Split: Train\n","    StandardTransform\n","Transform: Compose(\n","               ToTensor()\n","           )"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjLznvm8xqaT"},"outputs":[],"source":["class CNNClassifier(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","    self.cnn1 = nn.Conv2d(1, 32, kernel_size= 3, stride=1, padding=0)\n","    self.cnn2 = nn.Conv2d(32, 16, kernel_size= 3, stride=1)\n","    self.cnn3 = nn.Conv2d(16, 1, kernel_size= 1)\n","    self.linear = nn.Linear(25, 10)\n","\n","  def forward(self, x):\n","    assert(x.shape == (BATCH_SIZE, 1, 28, 28))\n","\n","    x =  self.cnn1(x)\n","    assert(x.shape == (BATCH_SIZE, 32, 26, 26))\n","\n","\n","    maxPool1 = nn.MaxPool2d(kernel_size= 2, stride=2)\n","    x = maxPool1(x)\n","    assert(x.shape == (BATCH_SIZE, 32, 13, 13))\n","    m = nn.ReLU()\n","    x = m(x)\n","\n","\n","    x = self.cnn2(x)\n","    assert(x.shape == (BATCH_SIZE, 16, 11, 11))\n","\n","\n","    maxPool2 = nn.MaxPool2d(kernel_size= 2, stride=2)\n","    x = maxPool2(x)\n","    assert(x.shape == (BATCH_SIZE, 16, 5, 5))\n","\n","    x = m(x)\n","\n","\n","    x = self.cnn3(x)\n","    assert(x.shape == (BATCH_SIZE, 1, 5, 5))\n","\n","    x =  m(x)\n","\n","\n","    x = torch.flatten(x, start_dim = 1)\n","    assert(x.shape == (BATCH_SIZE, 25))\n","\n","\n","    x = self.linear(x)\n","    assert(x.shape == (BATCH_SIZE, 10))\n","    return x\n","\n","model = CNNClassifier()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zu4Z0aptxqcu","outputId":"14c780da-f80c-48eb-d135-5e5a42faae33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Metrics Epoch 0 Loss 0.4118 Accuracy 0.8717\n","Test Metrics Epoch 0 Loss 0.2048 Accuracy 0.9362\n","Train Metrics Epoch 1 Loss 0.2293 Accuracy 0.9303\n","Test Metrics Epoch 1 Loss 0.1661 Accuracy 0.9477\n","Train Metrics Epoch 2 Loss 0.1966 Accuracy 0.9405\n","Test Metrics Epoch 2 Loss 0.1864 Accuracy 0.9450\n","Train Metrics Epoch 3 Loss 0.1813 Accuracy 0.9442\n","Test Metrics Epoch 3 Loss 0.1521 Accuracy 0.9548\n","Train Metrics Epoch 4 Loss 0.1691 Accuracy 0.9486\n","Test Metrics Epoch 4 Loss 0.1888 Accuracy 0.9394\n","Train Metrics Epoch 5 Loss 0.1600 Accuracy 0.9506\n","Test Metrics Epoch 5 Loss 0.1381 Accuracy 0.9574\n","Train Metrics Epoch 6 Loss 0.1527 Accuracy 0.9538\n","Test Metrics Epoch 6 Loss 0.1771 Accuracy 0.9434\n","Train Metrics Epoch 7 Loss 0.1477 Accuracy 0.9551\n","Test Metrics Epoch 7 Loss 0.1405 Accuracy 0.9549\n","Train Metrics Epoch 8 Loss 0.1434 Accuracy 0.9556\n","Test Metrics Epoch 8 Loss 0.1360 Accuracy 0.9584\n","Train Metrics Epoch 9 Loss 0.1395 Accuracy 0.9568\n","Test Metrics Epoch 9 Loss 0.1207 Accuracy 0.9616\n","Train Metrics Epoch 10 Loss 0.1367 Accuracy 0.9575\n","Test Metrics Epoch 10 Loss 0.1568 Accuracy 0.9500\n","Train Metrics Epoch 11 Loss 0.1315 Accuracy 0.9586\n","Test Metrics Epoch 11 Loss 0.1652 Accuracy 0.9493\n","Train Metrics Epoch 12 Loss 0.1300 Accuracy 0.9598\n","Test Metrics Epoch 12 Loss 0.1259 Accuracy 0.9623\n","Train Metrics Epoch 13 Loss 0.1282 Accuracy 0.9606\n","Test Metrics Epoch 13 Loss 0.1402 Accuracy 0.9543\n","Train Metrics Epoch 14 Loss 0.1258 Accuracy 0.9605\n","Test Metrics Epoch 14 Loss 0.1357 Accuracy 0.9582\n","Train Metrics Epoch 15 Loss 0.1231 Accuracy 0.9604\n","Test Metrics Epoch 15 Loss 0.1590 Accuracy 0.9479\n","Train Metrics Epoch 16 Loss 0.1229 Accuracy 0.9621\n","Test Metrics Epoch 16 Loss 0.1458 Accuracy 0.9530\n","Train Metrics Epoch 17 Loss 0.1208 Accuracy 0.9617\n","Test Metrics Epoch 17 Loss 0.1287 Accuracy 0.9591\n","Train Metrics Epoch 18 Loss 0.1183 Accuracy 0.9630\n","Test Metrics Epoch 18 Loss 0.1301 Accuracy 0.9602\n","Train Metrics Epoch 19 Loss 0.1161 Accuracy 0.9633\n","Test Metrics Epoch 19 Loss 0.1277 Accuracy 0.9590\n"]}],"source":["\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr = LR)\n","\n","torch.manual_seed(SEED)\n","\n","\n","for epoch in range(EPOCHS):\n","    accuracy_hist_train = 0\n","    auroc_hist_train = 0.0\n","    loss_hist_train = 0\n","    for x_batch, y_batch in train_dl:\n","        y_pred = model(x_batch)\n","\n","        loss = loss_fn(y_pred, y_batch)\n","\n","        l1_reg = torch.tensor(0.).to(y_batch.device)\n","        for i in model.parameters():\n","          l1_reg += i.abs().sum()\n","\n","        l2_reg = torch.tensor(0.).to(y_batch.device)\n","        for i in model.parameters():\n","          l2_reg += i.pow(2).sum()\n","\n","        loss += l1_reg * L1_WEIGHT +  l2_reg * L2_WEIGHT\n","\n","        loss.backward()\n","\n","        loss_hist_train += loss.item() * x_batch.size(0)\n","\n","        optimizer.step()\n","\n","        optimizer.zero_grad()\n","\n","\n","        is_correct = torchmetrics.Accuracy(task=\"multiclass\", num_classes = 10)(y_pred, y_batch).item() * x_batch.size(0)\n","\n","        accuracy_hist_train += is_correct\n","    accuracy_hist_train /= len(train_dl.dataset)\n","    loss_hist_train /= len(train_dl.dataset)\n","    print(f'Train Metrics Epoch {epoch} Loss {loss_hist_train:.4f} Accuracy {accuracy_hist_train:.4f}')\n","\n","    accuracy_hist_test = 0\n","    loss_hist_test = 00\n","\n","    with torch.no_grad():\n","      accuracy_hist_test = 0\n","      auroc_hist_test = 0.0\n","      for x_batch, y_batch in test_dl:\n","          y_batch_pred = model(x_batch)\n","\n","          loss = loss_fn(y_batch_pred, y_batch)\n","\n","          l1_reg = torch.tensor(0.).to(y_batch.device)\n","          for i in model.parameters():\n","            l1_reg += i.abs().sum()\n","\n","          l2_reg = torch.tensor(0.).to(y_batch.device)\n","          for i in model.parameters():\n","            l2_reg += i.pow(2).sum()\n","\n","          loss += l1_reg * L1_WEIGHT +  l2_reg * L2_WEIGHT\n","\n","          loss_hist_test += loss.item() * x_batch.size(0)\n","\n","          is_correct = torchmetrics.Accuracy(task=\"multiclass\", num_classes = 10)(y_batch_pred, y_batch).item() * x_batch.size(0)\n","\n","          accuracy_hist_test += is_correct\n","\n","      accuracy_hist_test /= len(test_dl.dataset)\n","      loss_hist_test /= len(test_dl.dataset)\n","      print(f'Test Metrics Epoch {epoch} Loss {loss_hist_test:.4f} Accuracy {accuracy_hist_test:.4f}')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}